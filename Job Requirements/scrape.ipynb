{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "bd9b9fa2e01573c04c615c80eb9deceb460a08e7f2fed43cdd24f3a908b6f3b1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.webdriver.common.by import By "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_url = \"https://www.naukri.com/{i}-jobs?k={i}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_data(url, path):\n",
    "    global file_name_count\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_xpath('//*[@id=\"root\"]/div[3]/div[4]/div/button').click()\n",
    "    soup = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "    results = soup.find(class_=\"list\")\n",
    "    job_elems = results.find_all(\"article\",class_=\"jobTuple bgWhite br4 mb-8\")\n",
    "    c = 1\n",
    "    for element in job_elems:\n",
    "        window_before = driver.window_handles[0]\n",
    "        try:\n",
    "            click_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '/html/body/div[1]/div[3]/div[2]/section[2]/div[2]/article[{0}]'.format(c))))\n",
    "        \n",
    "            click_button.click()\n",
    "            window_after = driver.window_handles[1]\n",
    "            driver.switch_to_window(window_after)\n",
    "            try:\n",
    "                time.sleep(2)\n",
    "                soup = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "                data_to_txt_file = {}\n",
    "                try:\n",
    "                    job_description = soup.find(class_=\"dang-inner-html\")\n",
    "                    data_to_txt_file[\"JOB DESCRIPTION\"] = job_description.get_text()\n",
    "                except Exception as e:\n",
    "                    print(\"JD\",e)\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    other_details = soup.find(class_=\"other-details\")\n",
    "                    details = other_details.find_all(class_ = \"details\")\n",
    "                    for detail in details:\n",
    "                        data_to_txt_file[detail.label.get_text().upper()] = detail.span.get_text()[:-1]\n",
    "                except Exception as e:\n",
    "                    print(\"OD\",e)\n",
    "                    continue\n",
    "\n",
    "                try:    \n",
    "                    education = soup.find(class_=\"education\")\n",
    "                    education_details = education.find_all(class_ = \"details\")\n",
    "                    data_to_txt_file[\"EDUCATION\"] = {}\n",
    "                    for detail in education_details:\n",
    "                        data_to_txt_file[\"EDUCATION\"][detail.label.get_text().upper()[:-2]] = detail.span.get_text()\n",
    "                except:\n",
    "                    print(\"ED\",e)\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    key_skill = soup.find(class_=\"key-skill\")\n",
    "                    all_a = key_skill.find_all(\"a\")\n",
    "                    data_to_txt_file[\"KEY SKILL\"] = []\n",
    "                    for a in all_a:\n",
    "                        data_to_txt_file[\"KEY SKILL\"].append(a.get_text())\n",
    "                except Exception as e:\n",
    "                    print(\"KS\",e)\n",
    "                    continue\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"Main page parser\",e)\n",
    "                continue\n",
    "\n",
    "            file_name = os.path.join(path, str(file_name_count) + \".json\")\n",
    "            with open(file_name, 'w') as outfile:\n",
    "                json.dump(data_to_txt_file, outfile)\n",
    "            driver.close()\n",
    "            c += 1\n",
    "            print(file_name_count)\n",
    "            file_name_count += 1\n",
    "            driver.switch_to_window(window_before)\n",
    "            time.sleep(1)\n",
    "        \n",
    "        except:\n",
    "            driver.close()\n",
    "            c += 1\n",
    "            driver.switch_to_window(window_before)\n",
    "            time.sleep(1)\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data():\n",
    "    searchKeyword = \"software-developer\"\n",
    "    directory = searchKeyword\n",
    "    parent_dir = \"D:/MSIT/Major Project/2nd Year/Job Recommendation\"\n",
    "    path = os.path.join(parent_dir, directory)\n",
    "    try:\n",
    "        os.mkdir(path)  \n",
    "    except FileExistsError:\n",
    "        print(\"file exist\")\n",
    "    pagenation_count = 1\n",
    "    global file_name_count\n",
    "    file_name_count = 1\n",
    "\n",
    "    while(file_name_count < 5001):\n",
    "        if(pagenation_count == 1):\n",
    "            url = \"https://www.naukri.com/{0}-jobs?k={0}\".format(searchKeyword)\n",
    "        else:\n",
    "            url = \"https://www.naukri.com/{0}-jobs-{1}?k={0}\".format(searchKeyword,pagenation_count)\n",
    "        print(url)\n",
    "        get_url_data(url, path)\n",
    "        pagenation_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_data()"
   ]
  }
 ]
}